Failure,Reason,Example
Chatbots, Racist and derogatory remarks in response to other Twitter user,Microsoft Tay
AI-powered recruiting tool,The AI system  was  hiring for technical roles (i.e. software developer) in a way that was not gender-neutral.,Amazon’s Recruiting Tool
Self Driving Car, A perosn was fatally struck by the test vehicle whilst pushing a bicycle across a four-lane road,Uber Test vehicle fatality
"AI powered ball-tracking technology,","The system repeatedly confused the ball with the linesman’s bald head, especially when the ball was in unclear regions",Inverness Caledonian Thistle F.C Ball Tracking System
Humanoid robot ,"Robot  displayed impressive dexterity on the stage, it tripped over the curtain and tumbled off the stage just as it was wrapping up",Boston Dynamics’s Robot Blooper
Facial Recognition,"40% of the matches of the systems were of people of colour, indicating that the technology is racially biased",Amazon’s Rekognition software
Improve pixelated low res Images,The system in some cases turned images into monster-like images of people.,Google Brain
Cognitive Computing System to detect Cancer,"The system was making erroneous, downright dangerous cancer treatment advice",IBM’s “Watson for Oncology
 AI algorithms to score students ," The algorithm scored the students based on the historical performance of individual secondary schools, which resulted in students receiving way lower than they had expected","The government of UK, in August 2020, substituted teachers with AI algorithms"
Gender Identifying tool,"There were huge built-in biases in the system,when typed in the word “professor,” it predicted a 98.4 percent probability for males. Meanwhile, “stupid” returned a 61.7 percent female prediction.",AI-powered tool 'Genderify' —
